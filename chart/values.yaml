# There should not be more than 1 SonarQube instance connected to the same database. Please set this value to 1 or 0 (in case you need to scale down programmatically).
replicaCount: 1

# Enable/disable Keycloak SSO integration
sso:
  enabled: false
  # name is needed for sso login screen "keycloak" of "P1 SSO"
  name: ""
  # The applicationid is the keycloak client id
  applicationid: ""
  # The providerid is pulled from the saml config
  providerid: ""
  # The loginUrl is pulled from the saml config
  loginUrl: ""
  # The loginUrl is pulled from the saml config
  secured: ""
  # default = "name", value override
  # mapname: ""
  # default = "login", value override
  # maplogin: ""
  # default = "email", value override
  # mapemail: ""
  # default = "group", value override
  # mapgroup: ""
  # serverBaseURL value is needed - ex host = https://sonarqube.dev.bigbang.mil
  serverBaseURL: ""
  # idpmetadataurl is needed to pull SAML configureation from keycloak realms
  idpmetadataurl: ""
  # image default = "registry1.dso.mil/ironbank/big-bang/base:2.1.0"
  image: ""

  # Configure resource requests and limits in the ./chart/templates/bigbang/sso/configure-sso.yaml job
  resources:
    limits:
      cpu: 100m
      memory: 256Mi
    requests:
      cpu: 100m
      memory: 256Mi

  # Configure security context in the ./chart/templates/bigbang/sso/configure-sso.yaml job
  containerSecurityContext:
    enabled: true
    fsGroup: 26
    runAsUser: 26
    runAsGroup: 26
    capabilities:
      drop:
      - ALL

# -- We are exposing only the keys that BigBang overrides from the upstream chart. Please refer to the [upstream chart](https://github.com/SonarSource/helm-chart-sonarqube/blob/master/charts/sonarqube/values.yaml) for other value configs.
upstream:
  ## declaring fullnameoverride to resolve pipeline virtual service failure
  fullnameOverride: "sonarqube-sonarqube"
  # Configure the edition of SonarQube Server to deploy: developer or enterprise
  # edition: ""
  # Set the chart to use the latest released SonarQube Community Build
  community:
    enabled: true
    buildNumber: "25.8.0.112029"

  postgresql:
    enabled: true
    postgresqlUsername: "sonarUser"
    postgresqlPassword: "sonarPass"
    postgresqlDatabase: "sonarDB"

    auth:
      enablePostgresUser: true
      username: "sonarUser"
      password: "sonarPass"
      database: "sonarDB"

    image:
      registry: registry1.dso.mil
      repository: ironbank/opensource/postgres/postgresql
      tag: "16.2"
      pullSecrets:
      - private-registry
    primary:
      extraEnvVars:
        - name: POSTGRES_DB
          value: sonarDB
      extraVolumeMounts:
        - name: runtime
          mountPath: /var/run/postgresql
      extraVolumes:
        - name: runtime
          emptyDir: {}
      persistence:
        size: 20Gi
        mountPath: /var/lib/postgresql

  image:
    repository: registry1.dso.mil/ironbank/sonarsource/sonarqube/sonarqube-community-build #registry1.dso.mil/ironbank/big-bang/sonarqube-10
    tag: 25.8.0.112029-community
    pullSecrets: []

  # Set security context for sonarqube pod.
  # The current section contains the default values set in a generic Kubernetes cluster. If you are using OpenShift, you should not set any specific fsGroup.
  securityContext:
    fsGroup: 1000
    runAsUser: 1000
    runAsGroup: 1000

  # Set security context for sonarqube container.
  # The current section contains the default values set in a generic Kubernetes cluster. If you are using OpenShift, you should not set any specific UID or GID to be used for the execution.
  containerSecurityContext:
    runAsGroup: 1000
    capabilities:
      drop:
      - ALL

  nginx:
    enabled: false

  readinessProbe:
    exec:
      command:
      - sh
      - -c
      - |
        #!/bin/bash
        # A Sonarqube container is considered ready if the status is UP, DB_MIGRATION_NEEDED or DB_MIGRATION_RUNNING
        # status about migration are added to prevent the node to be kill while sonarqube is upgrading the database.
        if curl -s http://localhost:{{ .Values.service.internalPort }}{{ .Values.readinessProbe.sonarWebContext | default (include "sonarqube.webcontext" .) }}api/system/status | grep -q -e '"status":"UP"' -e '"status":"DB_MIGRATION_NEEDED"' -e '"status":"DB_MIGRATION_RUNNING"'; then
          exit 0
        fi
        exit 1
    # Note that timeoutSeconds was not respected before Kubernetes 1.20 for exec probes
    timeoutSeconds: 90

  livenessProbe:
    exec:
      command:
      - sh
      - -c
      - |
        curl --silent --fail --output /dev/null --max-time {{ .Values.livenessProbe.timeoutSeconds | default 1 }} --header "X-Sonar-Passcode: $SONAR_WEB_SYSTEMPASSCODE" "http://localhost:{{ .Values.service.internalPort }}{{ .Values.livenessProbe.sonarWebContext | default (include "sonarqube.webcontext" .) }}api/system/liveness"

  initContainers:
    image: registry1.dso.mil/ironbank/big-bang/base:2.1.0
    # We allow the init containers to have a separate security context declaration because
    # the initContainer may not require the same as SonarQube.
    # Those default are used to match pod security standard restricted as least privileged approach
    securityContext:
      runAsGroup: 1000

    readOnlyRootFilesystem: true
    # We allow the init containers to have a separate resources declaration because
    # the initContainer does not take as much resources.
    resources:
      limits:
        memory: 300Mi
        cpu: 50m
      requests:
        memory: 300Mi
        cpu: 50m

  waitForDb:
    image: registry1.dso.mil/ironbank/opensource/postgres/postgresql:16.2

  initSysctl:
    enabled: false

    securityContext:
      capabilities:
        drop:
        - ALL

  prometheusExporter:
    image: registry1.dso.mil/ironbank/opensource/prometheus/jmx-exporter:1.0.1

  plugins:
    image: registry1.dso.mil/ironbank/sonarsource/sonarqube/sonarqube-community-build:25.8.0.112029-community #registry1.dso.mil/ironbank/big-bang/sonarqube-10:10.7.0-community

  monitoringPasscode: "define_it"

  ## Environment variables to attach to the pods
  ##
  # Big Bang addition - FIPS is not supported by Sonarqube so we have to disable the FIPS alignment at the JDK level
  # For additional Sonarqube pre-reqs see https://docs.sonarqube.org/latest/requirements/requirements/
  env:
  - name: JDK_JAVA_OPTIONS
    value: "-Dcom.redhat.fips=false"

  ## We usually don't make specific resource recommendations, as they are heavily dependant on
  ## the usage of SonarQube and the surrounding infrastructure.
  ## Those default are based on the default Web -Xmx1G -Xms128m and CE -Xmx2G -Xms128m and Search -Xmx2G -Xms2G settings of SQ sub processes
  ## Adjust these values to your needs, you can find more details on the main README of the chart.
  resources:
    limits:
      cpu: 1000m
    requests:
      cpu: 500m

  persistence:
    size: 20Gi

  # A custom sonar.properties file can be provided via dictionary.
  # For example:
  sonarProperties:
    sonar.forceAuthentication: true
    sonar.ce.javaAdditionalOpts: "-Dcom.redhat.fips=false"
    sonar.search.javaAdditionalOpts: "-Dcom.redhat.fips=false"
    sonar.web.javaAdditionalOpts: "-Dcom.redhat.fips=false"

  tests:
    image: bitnami/minideb-extras
    enabled: false
    resources: {}

  # For OpenShift set create=true to ensure service account is created.
  serviceAccount:
    create: true

# Big Bang Additions

## Bigbang security package kyverno will, by default, block images that don't originate from registry1.dso.mil
# curlContainerImage: curlimages/curl:latest
curlContainerImage: "registry1.dso.mil/ironbank/redhat/ubi/ubi9:9.6"

## Your FQDN will be ${ .Values.subdomain }.${ .Values.domain }
domain: dev.bigbang.mil
istio:
  # Toggle istio integration
  enabled: false
  hardened:
    enabled: false
    customAuthorizationPolicies: []
    outboundTrafficPolicyMode: "REGISTRY_ONLY"
    customServiceEntries: []
    tempo:
      enabled: true
      namespaces:
      - tempo
      principals:
      - cluster.local/ns/tempo/sa/tempo-tempo
    monitoring:
      enabled: true
      namespaces:
      - monitoring
      principals:
      - cluster.local/ns/monitoring/sa/monitoring-grafana
      - cluster.local/ns/monitoring/sa/monitoring-monitoring-kube-alertmanager
      - cluster.local/ns/monitoring/sa/monitoring-monitoring-kube-operator
      - cluster.local/ns/monitoring/sa/monitoring-monitoring-kube-prometheus
      - cluster.local/ns/monitoring/sa/monitoring-monitoring-kube-state-metrics
      - cluster.local/ns/monitoring/sa/monitoring-monitoring-prometheus-node-exporter
  # -- Default argocd peer authentication
  mtls:
    # -- STRICT = Allow only mutual TLS traffic,
    # PERMISSIVE = Allow both plain text and mutual TLS traffic
    mode: STRICT
  sonarqube:
    # Toggle vs creation
    enabled: true
    annotations: {}
    labels: {}
    gateways:
    - istio-system/main
    hosts:
    - sonarqube.{{ .Values.domain }}
  injection: disabled
monitoring:
  enabled: false

networkPolicies:
  enabled: false
  ingressLabels:
    app: istio-ingressgateway
    istio: ingressgateway
  egressHttps:
    enabled: true
  # Additional network policies
  # ref: https://kubernetes.io/docs/concepts/services-networking/network-policies/
  additionalPolicies: []

bbtests:
  enabled: false
  cypress:
    artifacts: true
    envs:
      cypress_url: "http://sonarqube-sonarqube:9000"
      cypress_url_setup: "http://sonarqube-sonarqube:9000/setup"
      cypress_user: "admin"
      cypress_password: "admin"
      cypress_new_password: "New_admin_password!2"
      cypress_timeout: "10000"
